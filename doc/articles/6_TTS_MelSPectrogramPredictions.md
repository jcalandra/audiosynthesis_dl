---


---

<h1 id="natural-tts-synthesis-by-conditioning-wavenet-on-mel-spectrogram-predictions">Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions</h1>
<p>Link of the article :<br>
<a href="https://arxiv.org/pdf/1712.05884.pdf">https://arxiv.org/pdf/1712.05884.pdf</a></p>
<h2 id="problematic">Problematic</h2>
<p>Description of Tacotron 2, a neural network for speech synthesis directly from text. 2 components :</p>
<ul>
<li>a recurrent sequence-to(sequence feature prediction network : maps character embedding to mel spectrograms.</li>
<li>a modified WaveNet model that act as a vocoder that maps spectrograms to time-domain waveforms.</li>
</ul>
<h2 id="model-architecture">Model Architecture</h2>
<ul>
<li>
<p><strong>Intermediate Feature Representation</strong><br>
The idea in this article is to train both component of the network separately. This representation by Mel Spectrogram is also easier to train than audio waveform as it is invariant within each frame. The representation of Mel-frequency spectrogram emphasis details in lower frequencies<br>
<strong>Griffin-Lim algorithm</strong> estimates phase informations, therefore enable time-domain conversion (with inverse short-time Fourier transform).</p>
</li>
<li>
<p><strong>Spectrogram Prediction Network</strong><br>
The network is composed of an encoder and decoder with attention.</p>
</li>
</ul>
<p><img src="https://cdn-images-1.medium.com/max/1200/1*fOfgv91uW0osDqddnJjdww.jpeg" alt="enter image description here"></p>
<p><strong>encoder</strong> : converts a character sequence into a hidden feature representation.<br>
<strong>decoder</strong> : Autoregressive reccurent neural network. Predict a spectrogram from the encoded input, one frame at a time.<br>
The concatenation of the decoder LSTM output and the attention context is also project down to a scalar and passed through a sigmoid activation to predict the probability that the output sequence has completed. Allow the network to dynamically determine when to terminate the generation.</p>
<ul>
<li><strong>WaveNet Vocoder</strong><br>
Different model than the one described in article 1.</li>
</ul>
<h2 id="training">Training</h2>
<ul>
<li>** Setup**<br>
first, the feature prediction network is trained on its own, then the WaveNet is trained independently on the output generated by the first network.<br>
Maximum-likelihood training procedure.</li>
</ul>
<h2 id="performances">Performances</h2>
<p>MOS of 4.53 for Tacotron2</p>

<table>
<thead>
<tr>
<th>System</th>
<th>MOS</th>
</tr>
</thead>
<tbody>
<tr>
<td>Parametric</td>
<td>3.492</td>
</tr>
<tr>
<td>Tacotron</td>
<td>4.001</td>
</tr>
<tr>
<td>Concatenative</td>
<td>4.166</td>
</tr>
<tr>
<td>WaveNet</td>
<td>4.341</td>
</tr>
<tr>
<td>Ground truth</td>
<td>4.582</td>
</tr>
<tr>
<td><strong>Tacotron2</strong></td>
<td><strong>4.526</strong></td>
</tr>
</tbody>
</table>
