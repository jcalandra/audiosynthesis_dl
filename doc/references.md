---


---

<h1 id="references">REFERENCES</h1>
<p>References read and used in the context of End of Studies internship about Sound synthesis and Sound modification using Deep Learning.</p>
<h2 id="research-papers-">Research papers :</h2>
<ul>
<li><strong>WaveNet : A Generative Model For Raw Audio</strong><a href="https://arxiv.org/pdf/1609.03499.pdf">https://arxiv.org/pdf/1609.03499.pdf</a></li>
<li><strong>Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders</strong><br>
<a href="https://arxiv.org/pdf/1704.01279.pdf">https://arxiv.org/pdf/1704.01279.pdf</a> – en lecture</li>
<li><strong>Neural Music Synthesis For Flexible Timbre Control</strong><br>
<a href="https://arxiv.org/pdf/1811.00223.pdf">https://arxiv.org/pdf/1811.00223.pdf</a> – à relire</li>
<li><strong>SampleRNN: An Unconditional End-To-End Neural Audio Generation Model</strong><br>
<a href="https://arxiv.org/pdf/1612.07837.pdf">https://arxiv.org/pdf/1612.07837.pdf</a> – à lire</li>
<li><strong>Tacotron: A Fully End-to-End Text-To-Speech Synthesis Model</strong><br>
<a href="https://arxiv.org/pdf/1703.10135.pdf">https://arxiv.org/pdf/1703.10135.pdf</a></li>
<li><strong>Describing Multimedia Content using Attention-based Encoder–Decoder Networks</strong><br>
<a href="https://arxiv.org/pdf/1507.01053.pdf">https://arxiv.org/pdf/1507.01053.pdf</a> – en lecture</li>
<li><strong>Natural TTS Synthesis By Conditioning WaveNet on Mel Spectrogram Predictions</strong><br>
<a href="https://arxiv.org/pdf/1712.05884.pdf">https://arxiv.org/pdf/1712.05884.pdf</a><br>
For a better understanding of Neural Networks :</li>
<li><strong>Deep Residual Learning for Image Recognition</strong><br>
<a href="https://arxiv.org/pdf/1512.03385.pdf">https://arxiv.org/pdf/1512.03385.pdf</a></li>
<li><strong>ImageNet Classification with Deep ConvolutionalNeural Networks</strong><br>
<a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf</a></li>
<li><strong>Real Time Emulation Of Parametric Guitar Tube Amplifier With Long Short Term Memory Neural Network</strong> <a href="https://arxiv.org/pdf/1804.07145.pdf">https://arxiv.org/pdf/1804.07145.pdf</a></li>
<li><strong>Deep Learning for Tube Amplifier Emulation</strong><br>
<a href="https://arxiv.org/pdf/1811.00334.pdf">https://arxiv.org/pdf/1811.00334.pdf</a></li>
</ul>
<blockquote>
<p>Further articles bellow</p>
</blockquote>
<ul>
<li><strong>Neural Discrete Representation Learning (VQ-VAE)</strong><br>
<a href="https://arxiv.org/pdf/1711.00937.pdf">https://arxiv.org/pdf/1711.00937.pdf</a></li>
<li><strong>Generating Interpretable Images with Controllable Structure (comparison GAN vs PixelRNN)</strong><br>
<a href="https://openreview.net/pdf?id=Hyvw0L9el">https://openreview.net/pdf?id=Hyvw0L9el</a></li>
<li><strong>FiLM: Visual Reasoning with a General Conditioning Layer</strong><br>
<a href="https://arxiv.org/pdf/1709.07871.pdf">https://arxiv.org/pdf/1709.07871.pdf</a></li>
<li><strong>Deep Autoregressive Networks</strong><br>
<a href="https://arxiv.org/pdf/1310.8499.pdf">https://arxiv.org/pdf/1310.8499.pdf</a></li>
</ul>
<h2 id="reports-">Reports :</h2>
<ul>
<li><strong>Nicolas Etcheverry’s internship</strong><br>
<a href="http://dept-info.labri.fr/~hanna/Stages/rapport-de-stage.pdf">http://dept-info.labri.fr/~hanna/Stages/rapport-de-stage.pdf</a></li>
</ul>
<h2 id="code-">Code :</h2>
<ul>
<li>
<p><strong>Github WaveNet</strong><br>
WaveNet implementation :<br>
<a href="https://github.com/ibab/tensorflow-wavenet">https://github.com/ibab/tensorflow-wavenet</a><br>
Magenta :<br>
<a href="https://github.com/tensorflow/magenta">https://github.com/tensorflow/magenta</a><br>
NSynth demo :<br>
<a href="https://github.com/tensorflow/magenta-demos/blob/master/jupyter-notebooks/NSynth.ipynb">https://github.com/tensorflow/magenta-demos/blob/master/jupyter-notebooks/NSynth.ipynb</a></p>
</li>
<li>
<p><strong>Github RNN</strong><br>
<a href="https://github.com/soroushmehr/sampleRNN_ICLR2017">https://github.com/soroushmehr/sampleRNN_ICLR2017</a></p>
</li>
<li>
<p><strong>Nicolas Etcheverry’s project</strong><br>
<a href="https://github.com/etcheverry/transferotron">https://github.com/etcheverry/transferotron</a></p>
</li>
</ul>
<h2 id="vulgarisation-articles">Vulgarisation articles</h2>
<ul>
<li><strong>TTS history</strong><br>
<a href="https://becominghuman.ai/into-a-better-speech-synthesis-technology-29411b64f2a2">https://becominghuman.ai/into-a-better-speech-synthesis-technology-29411b64f2a2</a><br>
<a href="https://medium.com/@saxenauts/speech-synthesis-techniques-using-deep-neural-networks-38699e943861">https://medium.com/@saxenauts/speech-synthesis-techniques-using-deep-neural-networks-38699e943861</a></li>
<li><strong>Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders</strong><br>
<a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">https://deepmind.com/blog/wavenet-generative-model-raw-audio/</a></li>
<li><strong>PixelRNN</strong><br>
<a href="https://github.com/tensorflow/magenta/blob/master/magenta/reviews/pixelrnn.md">https://github.com/tensorflow/magenta/blob/master/magenta/reviews/pixelrnn.md</a></li>
<li><strong>SampleRNN</strong><br>
<a href="http://deepsound.io/samplernn_first.html">http://deepsound.io/samplernn_first.html</a></li>
<li><strong>Deep Learning for Tube Amplifier Emulation</strong><br>
<a href="http://research.spa.aalto.fi/publications/papers/icassp19-deep/">http://research.spa.aalto.fi/publications/papers/icassp19-deep/</a></li>
</ul>
<p>-<strong>ANS Synthesizer</strong><br>
<a href="http://www.theremin.ru/archive/ans.htm">http://www.theremin.ru/archive/ans.htm</a></p>
<h2 id="definition-articles-">Definition articles :</h2>
<ul>
<li>
<p><strong>ANN</strong><br>
<a href="https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/">https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/</a></p>
</li>
<li>
<p><strong>Attention mechanism</strong><br>
<a href="https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb">https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb</a></p>
</li>
<li>
<p><strong>Autoencoders</strong><br>
<a href="https://colinraffel.com/talks/vector2018few.pdf">https://colinraffel.com/talks/vector2018few.pdf</a></p>
</li>
<li>
<p><strong>Bias&amp;Variance</strong><br>
<a href="https://medium.com/datadriveninvestor/bias-and-variance-in-machine-learning-51fdd38d1f86">https://medium.com/datadriveninvestor/bias-and-variance-in-machine-learning-51fdd38d1f86</a></p>
</li>
<li>
<p><strong>CNN</strong><br>
<a href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/">https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/</a></p>
</li>
<li>
<p><strong>Embedded Vectors</strong><br>
<a href="https://towardsdatascience.com/deep-learning-4-embedding-layers-f9a02d55ac12">https://towardsdatascience.com/deep-learning-4-embedding-layers-f9a02d55ac12</a></p>
</li>
<li>
<p><strong>GRU</strong><br>
<a href="https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be">https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be</a></p>
</li>
<li>
<p><strong>Latent Variable</strong><br>
<a href="https://www.theanalysisfactor.com/what-is-a-latent-variable/">https://www.theanalysisfactor.com/what-is-a-latent-variable/</a></p>
</li>
<li>
<p><strong>LSTM</strong><br>
<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p>
</li>
<li>
<p><strong>One Hot Encoding</strong><br>
<a href="https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f"> https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f</a></p>
</li>
<li>
<p><strong>Receptive field</strong><br>
<a href="https://www.quora.com/What-is-a-receptive-field-in-a-convolutional-neural-network">https://www.quora.com/What-is-a-receptive-field-in-a-convolutional-neural-network</a></p>
</li>
<li>
<p><strong>ResNet</strong><br>
<a href="https://towardsdatascience.com/understanding-residual-networks-9add4b664b03">https://towardsdatascience.com/understanding-residual-networks-9add4b664b03</a></p>
</li>
<li>
<p><strong>RNN</strong><br>
<a href="https://medium.com/explore-artificial-intelligence/an-introduction-to-recurrent-neural-networks-72c97bf0912">https://medium.com/explore-artificial-intelligence/an-introduction-to-recurrent-neural-networks-72c97bf0912</a></p>
</li>
<li>
<p><strong>Word2Vec</strong><br>
<a href="https://medium.com/explore-artificial-intelligence/word2vec-a-baby-step-in-deep-learning-but-a-giant-leap-towards-natural-language-processing-40fe4e8602ba">https://medium.com/explore-artificial-intelligence/word2vec-a-baby-step-in-deep-learning-but-a-giant-leap-towards-natural-language-processing-40fe4e8602ba</a></p>
</li>
</ul>
<h2 id="videos--yt">Videos &amp; YT</h2>
<h2 id="labs-projects--culture">Labs, Projects &amp; Culture</h2>
<ul>
<li>
<p><strong>Magenta</strong><br>
<a href="https://magenta.tensorflow.org/">https://magenta.tensorflow.org/</a><br>
<a href="https://ai.google/research/teams/brain/magenta/">https://ai.google/research/teams/brain/magenta/</a></p>
</li>
<li>
<p><strong>Metacreation Lab</strong><br>
<a href="http://metacreation.net/">http://metacreation.net/</a></p>
</li>
<li>
<p><strong>MatraLab</strong><br>
<a href="http://matralab.hexagram.ca/">http://matralab.hexagram.ca/</a></p>
</li>
</ul>
<h2 id="demos">Demos</h2>
<p>-<strong>PixelSynth</strong><br>
<a href="https://ojack.github.io/articles/pixelsynth/index.html">https://ojack.github.io/articles/pixelsynth/index.html</a></p>
<h2 id="hardware--computing">Hardware &amp; Computing</h2>
<ul>
<li><strong>A Full Hardware Guide to Deep Learning</strong><br>
<a href="http://timdettmers.com/2018/12/16/deep-learning-hardware-guide/">http://timdettmers.com/2018/12/16/deep-learning-hardware-guide/</a></li>
</ul>

