{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pict2Audio_color",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcalandra/audiosynthesis_dl/blob/master/src/Pict2Audio_color.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2bDMFdrIp9f",
        "colab_type": "text"
      },
      "source": [
        "# Pict2Audio : A Neural Network that associates Pictures to Audio Descriptors\n",
        "\n",
        "## Pict2Audio_color\n",
        "This is the independant code for the color neural network. This code aims to test the efficiency of every possibilities of databases and architectures for this neural network.\n",
        "\n",
        "**You will find the multilabel version at the following link :**\n",
        "[https://colab.research.google.com/drive/1_ZTdR2CG_eekUUtqAG9Bqa7RixHL8v93](https://colab.research.google.com/drive/1_ZTdR2CG_eekUUtqAG9Bqa7RixHL8v93)\n",
        "\n",
        "## Importation of the libraries\n",
        "\n",
        "First, we need to import all the package and libraries necessary to run the code.\n",
        "\n",
        "The backend Tensorflow is used with the library Keras to implement the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZFRXiCWomB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import  colorsys\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, BatchNormalization,Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from keras import optimizers\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing import image\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from keras import callbacks\n",
        "\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "\n",
        "\n",
        "print('tensorflow:', tf.__version__)\n",
        "print('keras:', keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdsYKWFeH6kq",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Importation of the Dataset :\n",
        "\n",
        "the dataset is imported from github, using the repository audiosynthesis_dl. In this repository, you can also find documentation about sound synthesis using Neural Networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK-IhlQAnK21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, import git repository\n",
        "! git clone https://github.com/jcalandra/audiosynthesis_dl.git\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdu2H9vq-PzX",
        "colab_type": "text"
      },
      "source": [
        "Then, run the following script in the same environment :\n",
        "\n",
        "https://colab.research.google.com/drive/1lJELWVC4DmQSNOw0fat4KrzTo_GmVbpZ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5LsHZgZDdGX",
        "colab_type": "text"
      },
      "source": [
        "To avoid downloading a heavy set of data on the computer, I chose to generate the pictures directly and load them from google colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwmaXP_6ClUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aroCrfQoFzVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## GLOBAL VALUES\n",
        "\n",
        "NB_PITCH = 12\n",
        "NB_COLOR = 8\n",
        "NB_THICK = 3\n",
        "NB_CLASS = NB_COLOR\n",
        "PICT_WIDTH = 400\n",
        "NB_CHANNEL = 3\n",
        "LINE_WIDTH = PICT_WIDTH//NB_PITCH #33\n",
        "\n",
        "NB_CARACTERISTICS = 1\n",
        "\n",
        "# number of versions for a same pitch\n",
        "NB_VERSION_TRAIN = 2\n",
        "NB_VERSION_VALIDATION = 1\n",
        "\n",
        "# number of trained and validation pictures\n",
        "NB_TRAIN = NB_VERSION_TRAIN*NB_COLOR*NB_PITCH*NB_THICK\n",
        "NB_VALIDATION = NB_VERSION_VALIDATION*NB_COLOR*NB_PITCH*NB_THICK"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqP7MVGtF4EG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## LOADING THE BASELINE\n",
        "\n",
        "baseline = cv2.imread('audiosynthesis_dl/data/base_quadrillage.png')\n",
        "#cv2_imshow(baseline)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDvJgznCcu98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## PICTURE GENERATION\n",
        "\n",
        "# generating exactly the same path line for every color, pitch and thickness\n",
        "\n",
        "def generate_pict(nb_version_pict, folder, outline_value, pic_type): # pic_type = [PITCH, THICK, COLOR] with 0 if no, 1 if yes\n",
        "  \"\"\" creates nb_pictures of pitch-lines and saves them permanently in the folder img_'folder'.\n",
        "      Folder has to be a string and nb_pict is an integer.\"\"\"\n",
        "  \n",
        "  # default values if pitches, thicknesses and/or colors don't change\n",
        "  height = (3%NB_PITCH)*LINE_WIDTH + (LINE_WIDTH + 5)//2\n",
        "  thickness = 6\n",
        "  sat = hue = val = 0\n",
        "  # default indices\n",
        "  pitch_ind = 0\n",
        "  thick_ind = 0\n",
        "  color_ind = 0\n",
        "  \n",
        "  # beginning value for thickness if there is a variation of thickness\n",
        "  if (pic_type[1] == 1):\n",
        "    thickness = 12\n",
        "  # tab of color values if there is a variation of colors\n",
        "  hueval_tab = [[(i*180)/(NB_COLOR//2), 90] for i in range(NB_COLOR//2)] + [[(i*180)/(NB_COLOR//2), 210] for i in range(NB_COLOR//2)]\n",
        "  #tab of available thicknesses if there is a variotion of thicknesses\n",
        "  thickness_tab = [2,7,12]\n",
        "  global_line_path = np.empty((PICT_WIDTH),dtype=int)\n",
        "  \n",
        "  for i in range (nb_version_pict) :\n",
        "    \n",
        "    # generation of lines path :   \n",
        "    outline = outline_value \n",
        "    delta = (LINE_WIDTH - (thickness*2))//2 + outline    \n",
        "    variation = np.random.randint(0,delta - outline)   # the line begin at a random point in delta\n",
        "    intervalle_max = np.random.randint(2,50)           # interval allowed to keep the same height between each variation\n",
        "    \n",
        "    for l in range(PICT_WIDTH):\n",
        "      intervalle = np.random.randint(1,intervalle_max) # to avoid a sharp variation, we keep the same variation height for each 'intervalle'\n",
        "      if (l%intervalle == 0) :                         # if we want to change the height of the line\n",
        "        tmp_var = np.random.randint(-1, 2)             # each variation is an increase or a decrease of 1 (or same height)\n",
        "        if abs(variation + tmp_var) < delta :\n",
        "          variation = variation + tmp_var\n",
        "        else :\n",
        "          variation = variation             \n",
        "      global_line_path[l] = PICT_WIDTH + variation\n",
        "    \n",
        "    # pitch affiliation :    \n",
        "    for p in range(NB_PITCH):\n",
        "      if (pic_type[0] == 1 ):\n",
        "        pitch_ind = 69 + p #69 is pitch for la440\n",
        "        height = p*LINE_WIDTH + (LINE_WIDTH + 5)//2       \n",
        "      line_path = global_line_path - height - 1\n",
        "\n",
        "      \n",
        "      # generation of the pictures. There are nb_version_pict*NB_COLOR*NB_PITCH pictures :\n",
        "      for m in range(NB_COLOR):  \n",
        "        \n",
        "        # creation of the baseline, quadrilled picture :       \n",
        "        line_image_rgb = baseline.copy()\n",
        "\n",
        "                \n",
        "        # color affiliation :\n",
        "        line_image_hsv = cv2.cvtColor(line_image_rgb, cv2.COLOR_RGB2HSV)\n",
        "        h, s, v = cv2.split(line_image_hsv)\n",
        "      \n",
        "        if( pic_type[2] == 1):\n",
        "          color_ind = m\n",
        "          color = hueval_tab[color_ind]\n",
        "          sat = 150\n",
        "          hue = color[0]\n",
        "          val = color[1]\n",
        "          \n",
        "        #thickness affiliation :\n",
        "        for t in range(NB_THICK): \n",
        "          thick_ind = t\n",
        "          thickness = thickness_tab[thick_ind]\n",
        "\n",
        "          for j in range(PICT_WIDTH):\n",
        "\n",
        "            # creation of the line :\n",
        "            if( line_path[j] > 0 and line_path[j] < 400 ) :\n",
        "              h[line_path[j]][PICT_WIDTH - j - 1] = hue      \n",
        "              s[line_path[j]][PICT_WIDTH - j - 1] = sat \n",
        "              v[line_path[j]][PICT_WIDTH - j - 1] = val \n",
        "\n",
        "            # and its thickness :\n",
        "            for k in range (thickness) :\n",
        "              if( line_path[j] - k > 0 and line_path[j] - k < 400 ) :\n",
        "                h[line_path[j] - k][PICT_WIDTH - j - 1] = hue \n",
        "                s[line_path[j] - k][PICT_WIDTH - j - 1] = sat\n",
        "                v[line_path[j] - k][PICT_WIDTH - j - 1] = val\n",
        "\n",
        "              if( line_path[j] + k > 0 and line_path[j] + k < 400 ) :\n",
        "                h[line_path[j] + k][PICT_WIDTH - j - 1] = hue\n",
        "                s[line_path[j] + k][PICT_WIDTH - j - 1] = sat\n",
        "                v[line_path[j] + k][PICT_WIDTH - j - 1] = val\n",
        "\n",
        "          line_image_hsv = cv2.merge((h,s,v))\n",
        "          line_image = cv2.cvtColor(line_image_hsv, cv2.COLOR_HSV2RGB)\n",
        "\n",
        "\n",
        "          cv2_imshow(line_image) #showing the images for tests\n",
        "          name = 'pitch'+str(pitch_ind)+ '_thick' + str(thick_ind) + '_color' + str(color_ind) +'_'+str(i) + '_'+folder+'.png'\n",
        "          print(name)\n",
        "\n",
        "          # save the picture in google colab :\n",
        "          cv2.imwrite('./audiosynthesis_dl/data/pitch_img/img_'+folder+'/'+ name, line_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H105AMhTvMtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('[INFO] generating training dataset...')\n",
        "generate_pict(NB_VERSION_TRAIN, 'train', 0, [1,1,1])\n",
        "print('[INFO] generating training dataset...')\n",
        "generate_pict(NB_VERSION_VALIDATION, 'validation', 0, [1,1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgWQoVexJylW",
        "colab_type": "text"
      },
      "source": [
        "## Loading the datas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl1ulRj9J7GW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## LOADING THE PICTURES\n",
        "\n",
        "#TODO : trouver un moyen d'optimiser\n",
        "\n",
        "imagePath_train = sorted(os.listdir( \"./audiosynthesis_dl/data/pitch_img/img_train\")[:])\n",
        "imagePath_validation = sorted(os.listdir( \"./audiosynthesis_dl/data/pitch_img/img_validation\")[:])\n",
        "\n",
        "print('[INFO] loading training dataset...')\n",
        "\n",
        "label_train = []\n",
        "label_validation = []\n",
        "\n",
        "\n",
        "img_train = np.empty((0,400,400,NB_CHANNEL))\n",
        "for imgP in imagePath_train :\n",
        "  if imgP.split(\".\")[-1] != \"git\" and imgP.split(\".\")[-1] != \"gitignore\":\n",
        "    img = image.load_img( \"./audiosynthesis_dl/data/pitch_img/img_train/\"+imgP, \n",
        "                             target_size=(400, 400),\n",
        "                             color_mode='rgb')\n",
        "    #img_flip = np.fliplr(img)\n",
        "    img_train = np.concatenate((img_train,np.reshape(img,(1,400,400,NB_CHANNEL))),axis=0)\n",
        "    #img_train = np.concatenate((img_train,np.reshape(img_flip,(1,400,400,NB_CHANNEL))),axis=0)\n",
        "    l = imgP.split(\"_\")\n",
        "    labels = l[2:2+NB_CARACTERISTICS]\n",
        "    label_train.append(labels)\n",
        "    #label_train.append(labels)\n",
        "    \n",
        "\n",
        "print('[INFO] loading validation dataset...')\n",
        "img_validation = np.empty((0,400,400,NB_CHANNEL))\n",
        "for imgP in imagePath_validation :\n",
        "  if imgP.split(\".\")[-1] != \"git\" and imgP.split(\".\")[-1] != \"gitignore\":\n",
        "    img = image.load_img( \"./audiosynthesis_dl/data/pitch_img/img_validation/\"+imgP, \n",
        "                             target_size=(400, 400),\n",
        "                             color_mode='rgb')\n",
        "    #img_flip = np.fliplr(img)\n",
        "    img_validation = np.concatenate((img_validation,np.reshape(img,(1,400,400,NB_CHANNEL))),axis=0)\n",
        "    #img_validation = np.concatenate((img_validation,np.reshape(img_flip,(1,400,400,NB_CHANNEL))),axis=0)\n",
        "    l = imgP.split(\"_\")\n",
        "    labels = l[2:2+NB_CARACTERISTICS]\n",
        "    label_validation.append(labels)\n",
        "    #label_validation.append(labels)\n",
        "\n",
        "\n",
        "print('img_train.shape=', img_train.shape)\n",
        "print('img_validation.shape=', img_validation.shape)\n",
        "\n",
        "\n",
        "print(label_validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAkgzKXpTorp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CONVERTING THE DATA\n",
        "\n",
        "def converting_data(img_tab) :\n",
        "  \"\"\" convert the data in float between 0 et 1\"\"\"\n",
        "  # Convert to float\n",
        "  img_tab = img_tab.astype('float32')\n",
        "  # Normalize inputs from [0; 255] to [0; 1]\n",
        "  imgnorm_tab = img_tab / 255\n",
        "\n",
        "  return imgnorm_tab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "addzNAZwRqW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## MIXING THE DATA FOR A GOOD LEARNING\n",
        "def shuffle_data(img_tab, label_tab, nb_pict) :\n",
        "  \"\"\" create shuffled tabs of data and corresponding labels \"\"\"\n",
        "  imgnorm_tab = converting_data(img_tab)\n",
        "    \n",
        "  xy_tab = []\n",
        "  for i in range(nb_pict):\n",
        "    label_tab_i = []\n",
        "    color = int(label_tab[i][0].split('color')[1]) #labels are converted into integer between 0 and the number of classes\n",
        "    label_tab_i.append(color)\n",
        "    \n",
        "    xy = [imgnorm_tab[i],label_tab_i]\n",
        "    xy_tab.append(xy)\n",
        "    \n",
        "  random.shuffle(xy_tab)\n",
        "  \n",
        "  x_tab = np.empty((nb_pict,400,400,NB_CHANNEL))\n",
        "  y_tab = np.empty((nb_pict,NB_CARACTERISTICS))\n",
        "  \n",
        "  for i in range(nb_pict):\n",
        "    x_tab[i] = xy_tab[i][0]\n",
        "    y_tab[i] = xy_tab[i][1]\n",
        "  \n",
        "  \n",
        "  del imgnorm_tab\n",
        "  del xy_tab\n",
        "  return [x_tab,y_tab]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzNoY-J-vT61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.copy(img_train)\n",
        "x_validation = np.copy(img_validation)\n",
        "y_train = np.copy((label_train,NB_CARACTERISTICS))\n",
        "y_validation = np.copy((label_validation,NB_CARACTERISTICS))\n",
        "\n",
        "print('[INFO] shuffle datasets...')\n",
        "[x_train, y_train] = shuffle_data(img_train, label_train, NB_TRAIN)\n",
        "[x_validation, y_validation] = shuffle_data(img_validation, label_validation, NB_VALIDATION)\n",
        "\n",
        "print('x_train.shape=', x_train.shape)\n",
        "print('x_validation.shape=', x_validation.shape)\n",
        "\n",
        "del img_train\n",
        "del img_validation\n",
        "del label_train\n",
        "del label_validation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tWxxYVuzZZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## GENERATION OF THE COLOR FEATURES TABS\n",
        "\n",
        "def gen_features_tabs(y_tab, y_feature, i_feature) :\n",
        "  ''' generate a tab containing the labels for one specific feature '''\n",
        "  for i in range(len(y_tab)) :\n",
        "    y_feature[i] = y_tab[i][i_feature]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfvzhOqWeXLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_color = np.empty(NB_TRAIN)\n",
        "y_validation_color = np.empty(NB_VALIDATION)\n",
        "gen_features_tabs(y_train, y_train_color, 0)\n",
        "gen_features_tabs(y_validation, y_validation_color, 0)\n",
        "\n",
        "print('[INFO] generating color label tabs...')\n",
        "print('y_train_color.shape=', y_train_color.shape)\n",
        "print('y_validation_color.shape=', y_validation_color.shape)\n",
        "\n",
        "print(y_validation_color)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suwrEgCRecd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert class vectors to binary class matrices (\"one hot encoding\")\n",
        "\n",
        "print('[INFO] converting class vectors...')\n",
        "y_train_color = keras.utils.to_categorical(y_train_color, NB_COLOR)\n",
        "y_validation_color = keras.utils.to_categorical(y_validation_color, NB_COLOR)\n",
        "\n",
        "\n",
        "print('y_train_pitch.shape =', y_train_color.shape)\n",
        "print('y_validation_pitch.shape = ', y_validation_color.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3Z7-P81KBZg",
        "colab_type": "text"
      },
      "source": [
        "## The Convolutional Neural Network\n",
        "\n",
        "Now we need to create and compile the CNN that will classify our datas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTQtbNLt9Th6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CREATION OF THE COLOR NEURAL NETWORK\n",
        "\n",
        "print('[INFO] training COLOR NETWORK...')\n",
        "\n",
        "model_color = Sequential()\n",
        "\n",
        "model_color.add(Conv2D(filters=32, kernel_size=(3,3), strides=1, padding='valid', activation='relu'))\n",
        "model_color.add(BatchNormalization(axis=-1))\n",
        "model_color.add(MaxPooling2D(pool_size=(3,3), strides=None, padding='valid', data_format=None))\n",
        "\n",
        "model_color.add(Conv2D(filters=64, kernel_size=(3,3), strides=1, padding='valid', activation='relu'))\n",
        "model_color.add(BatchNormalization(axis=-1))\n",
        "model_color.add(MaxPooling2D(pool_size=(3,3), strides=None, padding='valid', data_format=None))\n",
        "\n",
        "model_color.add(Conv2D(filters=128, kernel_size=(3,3), strides=1, padding='valid', activation='relu'))\n",
        "model_color.add(BatchNormalization(axis=-1))\n",
        "model_color.add(MaxPooling2D(pool_size=(3,3), strides=None, padding='valid', data_format=None))\n",
        "model_color.add(Dropout(0.75))\n",
        "\n",
        "# first (and only) set of FC => RELU layers\n",
        "model_color.add(Flatten())\n",
        "model_color.add(Dense(64))\n",
        "model_color.add(Activation(\"relu\"))\n",
        "model_color.add(BatchNormalization())\n",
        " \n",
        "# use a *sigmoid* activation for multi-label classification\n",
        "model_color.add(Dense(NB_CLASS))\n",
        "model_color.add(Activation('softmax'))  \n",
        "  \n",
        "  \n",
        "opt_color = keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model_color.compile(loss='categorical_crossentropy', optimizer= opt_color, metrics=['accuracy'])\n",
        "cb = callbacks.ModelCheckpoint('model_color.h5', save_best_only=True, period=1)\n",
        "\n",
        "hist = model_color.fit(x_train, y_train_color, validation_data=(x_validation, y_validation_color), epochs= 200, batch_size=32, callbacks = [cb])\n",
        "loss_and_metrics = model_color.evaluate(x_validation, y_validation_color, batch_size=32)\n",
        "print('loss =', loss_and_metrics[0],'accuracy =', loss_and_metrics[1]);\n",
        "\n",
        "model_color.summary();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yogo6mitK4sW",
        "colab_type": "text"
      },
      "source": [
        "## Results\n",
        "\n",
        "Only color (8) :\n",
        "\n",
        "* data : 30x12 train +10x12validation\n",
        "* 2D(34)+MaxPool+2D(64)+MaxPool+2D(128)+MaxPool+Dropout(0.75)+Dense(64)+Dense(8)\n",
        "* epoch = 100 batch size = 32\n",
        "* loss: 0.0014 - acc: 1.0000 - val_loss: 1.2460e-04 - val_acc: 1.0000\n",
        "\n",
        "\n",
        "color(8) + thick(6) :\n",
        "* data : 60x12(train)+15x12(validation)\n",
        "* 2D(34)+2D(34)+MaxPool + 2D(64)+2D(64)+MaxPool + 2D(128)+2D(128)+MaxPool+Dropout(0.75)+\n",
        "Dense(64)+Dense(8)\n",
        "* epoch = 100, batch size = 32\n",
        "* loss: 5.9750e-04 - acc: 1.0000 - val_loss: 4.0895e-05 - val_acc: 1.0000\n",
        "\n",
        "\n",
        "color(8) + pitch(12) :\n",
        "* data : 3x8x12x2 train +3x8x12x1 validation\n",
        "* 2D(34)+MaxPool+2D(64)+MaxPool+2D(128)+MaxPool+Dropout(0.75)+Dense(64)+Dense(8)\n",
        "opt = adam with lr=0.0001\n",
        "* epoch = 50 batch size = 32\n",
        "* loss: 0.2398 - acc: 0.9219 - val_loss: 0.1871 - val_acc: 0.9444\n",
        "\n",
        "color(8)+thick(3)+pitch(12):\n",
        "*  data : 3x8x12x2 train +3x8x12x1 validation\n",
        "* 2D(34)+MaxPool+2D(64)+MaxPool+2D(128)+MaxPool+Dropout(0.75)+Dense(64)+Dense(8)\n",
        "opt = adam with lr=0.0001\n",
        "* epoch = 100 batch size = 32\n",
        "* loss: 0.2398 - acc: 0.9219 - val_loss: 0.1871 - val_acc: 0.9444\n",
        "\n",
        "color(8)+thick(3)+pitch(12):\n",
        "*  data : 3x8x12x2 train +3x8x12x1 validation\n",
        "* 2D(34)+MaxPool+2D(64)+MaxPool+2D(128)+MaxPool+Dropout(0.75)+Dense(64)+Dense(8)\n",
        "opt = adam with lr=0.00001\n",
        "* version 1 :\n",
        " * lr=0.00001 epoch = 500 batch size = 32\n",
        " * loss: 0.1058 - acc: 0.9688 - val_loss: 0.1105 - val_acc: 0.9583\n",
        "* version 2 :\n",
        " * lr=0.00001 epoch = 1000 batch size = 32\n",
        " * loss: 0.0639 - acc: 0.9774 - val_loss: 0.0858 - val_acc: 0.9653\n",
        "* version 3:\n",
        " * lr=0.00005 epoch = 700 batch size = 32\n",
        " * train loss: 0.0767 - train accuracy: 0.9705 - validation loss: 0.0698 - validation acc: 0.9722 à l'epoch 640\n",
        "* version 4:\n",
        " * lr=0.000035 epoch = 700 batch size = 32\n",
        " * train loss: 0.0958 - train accuracy: 0.9653 - validation loss: 0.0731 - validation acc: 0.9792 à l'epoch 330\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhAg7J3CBN1S",
        "colab_type": "text"
      },
      "source": [
        "## Graphics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbZhQDs2WRYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUQuRaXnNdf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the trained convolutional neural network and the multi-label binarizer\n",
        "print(\"[INFO] loading network...\")\n",
        "model = load_model('model_color.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azp5XerEBG1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hist.history['acc'])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS8GpqWVrRWS",
        "colab_type": "text"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WZigOtH0shF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_accuracy(y_tab, y_guessed):\n",
        "  accuracy_sum = 0\n",
        "  for i in range(len(y_tab)) :\n",
        "    if(y_tab[i] == y_guessed[i]):\n",
        "      accuracy_sum += 1\n",
        "  accuracy = accuracy_sum / len(y_tab)\n",
        "  print('accuracy = ', accuracy)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F68w_o8rQlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NB_VERSION_TESTGEN = 1\n",
        "NB_TESTGEN = NB_THICK*NB_COLOR*NB_PITCH*NB_VERSION_TESTGEN\n",
        "\n",
        "print(\"[INFO] generating testgen dataset...\")\n",
        "generate_pict(NB_VERSION_TESTGEN, 'testgen',0, [1,1,1])\n",
        "\n",
        "label_testgen = []\n",
        "\n",
        "print(\"[INFO] loading the testgen dataset...\")\n",
        "img_testgen = np.empty((0,400,400,NB_CHANNEL))\n",
        "for imgP in sorted(os.listdir( \"./audiosynthesis_dl/data/pitch_img/img_testgen\")[:]) :\n",
        "  if imgP.split(\".\")[-1] != \"git\" and imgP.split(\".\")[-1] != \"gitignore\":\n",
        "    img = image.load_img( \"./audiosynthesis_dl/data/pitch_img/img_testgen/\"+imgP, \n",
        "                             target_size=(400, 400),\n",
        "                             color_mode='rgb')\n",
        "    img_testgen = np.concatenate((img_testgen,np.reshape(img,(1,400,400,NB_CHANNEL))),axis=0)\n",
        "    l = imgP.split(\"_\")\n",
        "    labels = l[2:2+NB_CARACTERISTICS]\n",
        "    label_testgen.append(labels)\n",
        "\n",
        "\n",
        "x_testgen = np.copy(img_testgen)\n",
        "y_testgenstat = np.copy((label_testgen,NB_CARACTERISTICS))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9piszOVsy6vX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"[INFO] shuffle testgen dataset...\")\n",
        "[x_testgen, y_testgenstat] = shuffle_data(img_testgen, label_testgen, NB_TESTGEN)  \n",
        "\n",
        "# load the trained convolutional neural network\n",
        "print(\"[INFO] loading network...\")\n",
        "model = load_model('model_color.h5')\n",
        "\n",
        "y_testgen = model.predict_classes(x_testgen)\n",
        "\n",
        "print('x_testgen.shape=', x_testgen.shape)\n",
        "print('y_testgenstat.shape=', y_testgenstat.shape)\n",
        "\n",
        "# show the inputs and predicted outputs\n",
        "for i in range(len(y_testgen)):\n",
        "  print(\"label y_testgen[%s] = %s\" % (i, y_testgen[i]))\n",
        "  \n",
        "test_accuracy(y_testgenstat, y_testgen)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGdk_H2okkPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 3;\n",
        "print('x_testgen.shape', x_testgen.shape, 'dtype', x_testgen.dtype)\n",
        "print('y_testgen[{}]={}'.format(i, y_testgen[i]))\n",
        "print('y_testgenstat[{}]={}'.format(i, y_testgenstat[i]))\n",
        "plt.imshow(x_testgen[i,:].reshape(400,400,NB_CHANNEL), cmap = matplotlib.cm.binary)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "plt.gcf().clear()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijNJKy0e76Pf",
        "colab_type": "text"
      },
      "source": [
        "## Sound synthesis according to the labelisation\n",
        "\n",
        "full independant code here : https://colab.research.google.com/drive/1KzM-NMSlj87XU_--cifmipAuYd57zZc4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU3JnGehU915",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math as m\n",
        "import IPython"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL2cUtdjbSFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "volume = 0.5     # range [0.0, 1.0]\n",
        "fs = 44100       # sampling rate, Hz, must be integer\n",
        "duration = 4.0   # in seconds, may be float\n",
        "f0 = 440.0        # sine frequency, Hz, may be float\n",
        "label = 0 # default value, take the one given by the neural network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKQOZlLxVcRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sinusoid(label, duration) :\n",
        "  \"\"\" generate an audio of a sinusoid \"\"\"\n",
        "  samples = []\n",
        "  fm  =  (2**(0/12))*f0\n",
        "  print(fm)\n",
        "  # generate samples\n",
        "  for i in range(int(fs*duration)) :\n",
        "    t = i/fs # seconds\n",
        "    a = 2*m.pi*fm*t # radians\n",
        "    v = volume*m.sin(a)\n",
        "    for j in range(1,label+1):\n",
        "      b = 2*m.pi*j*fm*t\n",
        "      v += (volume/j)*(m.sin(b))\n",
        "    samples.append(v)\n",
        "  return samples\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plvUClchyeHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 4\n",
        "label_i = y_testgen[i]\n",
        "\n",
        "sin = sinusoid(label_i, duration)\n",
        "IPython.display.Audio(sin, rate=fs)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}